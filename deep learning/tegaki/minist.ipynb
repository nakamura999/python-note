{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2481 - accuracy: 0.9246 - val_loss: 0.1126 - val_accuracy: 0.9640\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1031 - accuracy: 0.9691 - val_loss: 0.0813 - val_accuracy: 0.9748\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0759 - accuracy: 0.9770 - val_loss: 0.0814 - val_accuracy: 0.9763\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0607 - accuracy: 0.9819 - val_loss: 0.0940 - val_accuracy: 0.9740\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0504 - accuracy: 0.9848 - val_loss: 0.0856 - val_accuracy: 0.9789\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0438 - accuracy: 0.9869 - val_loss: 0.1007 - val_accuracy: 0.9766\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0391 - accuracy: 0.9883 - val_loss: 0.0721 - val_accuracy: 0.9825\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0328 - accuracy: 0.9908 - val_loss: 0.0893 - val_accuracy: 0.9821\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0317 - accuracy: 0.9909 - val_loss: 0.0919 - val_accuracy: 0.9813\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0312 - accuracy: 0.9913 - val_loss: 0.0938 - val_accuracy: 0.9818\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0282 - accuracy: 0.9919 - val_loss: 0.0858 - val_accuracy: 0.9818\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.1023 - val_accuracy: 0.9825\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.1110 - val_accuracy: 0.9824\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.1134 - val_accuracy: 0.9818\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.1180 - val_accuracy: 0.9814\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0210 - accuracy: 0.9944 - val_loss: 0.1184 - val_accuracy: 0.9851\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 0.1282 - val_accuracy: 0.9826\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0199 - accuracy: 0.9946 - val_loss: 0.1407 - val_accuracy: 0.9830\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0198 - accuracy: 0.9949 - val_loss: 0.1305 - val_accuracy: 0.9830\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.1305 - val_accuracy: 0.9844\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0180 - accuracy: 0.9957 - val_loss: 0.1343 - val_accuracy: 0.9821\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.1478 - val_accuracy: 0.9822\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.1400 - val_accuracy: 0.9811\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0180 - accuracy: 0.9956 - val_loss: 0.1436 - val_accuracy: 0.9822\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 0.1370 - val_accuracy: 0.9824\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 0.1422 - val_accuracy: 0.9845\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.1551 - val_accuracy: 0.9825\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.1348 - val_accuracy: 0.9841\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.1387 - val_accuracy: 0.9848\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 0.1591 - val_accuracy: 0.9829\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.1713 - val_accuracy: 0.9838\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 0.1730 - val_accuracy: 0.9830\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.1539 - val_accuracy: 0.9855\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.1673 - val_accuracy: 0.9834\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 0.1785 - val_accuracy: 0.9834\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.1726 - val_accuracy: 0.9833\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.1948 - val_accuracy: 0.9825\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.1731 - val_accuracy: 0.9836\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.1874 - val_accuracy: 0.9843\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.1853 - val_accuracy: 0.9850\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.1876 - val_accuracy: 0.9856\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.1832 - val_accuracy: 0.9851\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.1852 - val_accuracy: 0.9834\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.2024 - val_accuracy: 0.9844\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.1966 - val_accuracy: 0.9843\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.2079 - val_accuracy: 0.9832\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0114 - accuracy: 0.9978 - val_loss: 0.2062 - val_accuracy: 0.9852\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.2130 - val_accuracy: 0.9840\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.2199 - val_accuracy: 0.9839\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.2181 - val_accuracy: 0.9848\n",
      "10000/10000 [==============================] - 1s 64us/step\n",
      "正解率= 0.9847999811172485 loss= 0.2180957844857398\n"
     ]
    }
   ],
   "source": [
    "# MLPでMNISTの分類問題に挑戦\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 入力と出力を指定\n",
    "in_size = 28 * 28\n",
    "out_size = 10\n",
    "\n",
    "# MNISTのデータを読み込み --- (*1)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# データを28*28=784の一次元配列に変換\n",
    "X_train = X_train.reshape(-1, 784).astype('float32') / 255\n",
    "X_test = X_test.reshape(-1, 784).astype('float32') / 255\n",
    "# ラベルデータをone-hotベクトルに直す\n",
    "y_train = keras.utils.to_categorical(y_train.astype('int32'),10)\n",
    "y_test = keras.utils.to_categorical(y_test.astype('int32'),10)\n",
    "\n",
    "# MLPモデル構造を定義 --- (*2)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(in_size,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(out_size, activation='softmax'))\n",
    "\n",
    "# モデルをコンパイル --- (*3)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 学習を実行 --- (*4)\n",
    "hist = model.fit(X_train, y_train,\n",
    "          batch_size=128, \n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "# モデルを評価 --- (*5)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('正解率=', score[1], 'loss=', score[0])\n",
    "\n",
    "# 学習の様子をグラフへ描画 --- (*6)\n",
    "# 正解率の推移をプロット\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# ロスの推移をプロット\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
